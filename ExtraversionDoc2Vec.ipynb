{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "import os, codecs\n",
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics as skmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify model with personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/personality-normalized-word2vec-norm.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1039, 186)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    529\n",
       "1    510\n",
       "Name: extraversion_m, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.extraversion_m.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_w2v_data, test_w2v_data = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    target_names = ['no', 'yes']\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    cm = confusion_matrix(target, predictions)\n",
    "    print('confusion matrix\\n %s' % cm)\n",
    "    print('(row=expected, col=predicted)')\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized, title + ' Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(vectorizer, classifier, data):\n",
    "    data_features = vectorizer.transform(data['formatted_text'])\n",
    "    predictions = classifier.predict(data_features)\n",
    "    target = data['extraversion_m']\n",
    "    evaluate_prediction(predictions, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    if text is np.nan:\n",
    "        return []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tagged = train_w2v_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['formatted_text']), tags=[r.extraversion_m]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tagged = test_w2v_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['formatted_text']), tags=[r.extraversion_m]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-11 14:07:56,983 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-05-11 14:07:56,984 : INFO : collecting all words and their counts\n",
      "2017-05-11 14:07:56,985 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2017-05-11 14:07:57,306 : INFO : collected 43446 word types and 2 unique tags from a corpus of 727 examples and 1472087 words\n",
      "2017-05-11 14:07:57,307 : INFO : Loading a fresh vocabulary\n",
      "2017-05-11 14:07:57,398 : INFO : min_count=5 retains 13634 unique words (31% of original 43446, drops 29812)\n",
      "2017-05-11 14:07:57,398 : INFO : min_count=5 leaves 1421890 word corpus (96% of original 1472087, drops 50197)\n",
      "2017-05-11 14:07:57,438 : INFO : deleting the raw counts dictionary of 43446 items\n",
      "2017-05-11 14:07:57,441 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-05-11 14:07:57,442 : INFO : downsampling leaves estimated 1039507 word corpus (73.1% of prior 1421890)\n",
      "2017-05-11 14:07:57,444 : INFO : estimated required memory for 13634 words and 5 dimensions: 7362400 bytes\n",
      "2017-05-11 14:07:57,499 : INFO : resetting layer weights\n",
      "2017-05-11 14:07:57,630 : INFO : training model with 1 workers on 13634 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-05-11 14:07:57,631 : INFO : expecting 727 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-05-11 14:07:58,638 : INFO : PROGRESS: at 3.45% examples, 723894 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:07:59,645 : INFO : PROGRESS: at 6.93% examples, 723925 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:00,645 : INFO : PROGRESS: at 10.46% examples, 722289 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:01,647 : INFO : PROGRESS: at 13.93% examples, 721988 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:02,652 : INFO : PROGRESS: at 17.35% examples, 722647 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:03,652 : INFO : PROGRESS: at 20.99% examples, 722188 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:04,653 : INFO : PROGRESS: at 24.44% examples, 722458 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:05,659 : INFO : PROGRESS: at 27.89% examples, 722593 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:06,665 : INFO : PROGRESS: at 31.51% examples, 722727 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:07,669 : INFO : PROGRESS: at 35.03% examples, 722682 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:08,672 : INFO : PROGRESS: at 38.49% examples, 722724 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:09,677 : INFO : PROGRESS: at 41.95% examples, 722961 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:10,681 : INFO : PROGRESS: at 45.56% examples, 723174 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:11,683 : INFO : PROGRESS: at 49.04% examples, 723372 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:12,687 : INFO : PROGRESS: at 52.45% examples, 723343 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:13,697 : INFO : PROGRESS: at 56.08% examples, 723010 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:14,698 : INFO : PROGRESS: at 59.55% examples, 723002 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:15,706 : INFO : PROGRESS: at 63.01% examples, 723116 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:16,712 : INFO : PROGRESS: at 66.58% examples, 723035 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:17,719 : INFO : PROGRESS: at 70.14% examples, 722995 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:18,728 : INFO : PROGRESS: at 73.64% examples, 722892 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:19,730 : INFO : PROGRESS: at 76.99% examples, 722912 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:20,736 : INFO : PROGRESS: at 80.66% examples, 722991 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:21,742 : INFO : PROGRESS: at 84.17% examples, 722765 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:22,742 : INFO : PROGRESS: at 87.54% examples, 722813 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:23,743 : INFO : PROGRESS: at 91.16% examples, 722893 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:24,746 : INFO : PROGRESS: at 94.65% examples, 722860 words/s, in_qsize 2, out_qsize 0\n",
      "2017-05-11 14:08:25,747 : INFO : PROGRESS: at 98.07% examples, 722902 words/s, in_qsize 1, out_qsize 0\n",
      "2017-05-11 14:08:26,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-05-11 14:08:26,272 : INFO : training on 29441740 raw words (20698345 effective words) took 28.6s, 722741 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.6 s, sys: 242 ms, total: 51.9 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainsent = train_tagged.values\n",
    "testsent = test_tagged.values\n",
    "\n",
    "# simple gensim doc2vec api\n",
    "doc2vec_model = Doc2Vec(trainsent, workers=1, size=5, iter=20, dm=1)\n",
    "\n",
    "train_targets, train_regressors = zip(\n",
    "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in trainsent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1422\n",
    "\n",
    "doc2vec_model.seed = seed\n",
    "doc2vec_model.random = random.RandomState(seed)\n",
    "\n",
    "\n",
    "test_targets, test_regressors = zip(\n",
    "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in testsent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "force = False\n",
    "model_trainer = RandomizedSearchCV(\n",
    "    n_iter=1, \n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_distributions={\n",
    "        \"criterion\": [\"gini\"],\n",
    "        \"n_estimators\": [1000],\n",
    "        \"max_features\": [\"log2\"],\n",
    "        \"max_depth\": [None],\n",
    "        \"bootstrap\": [True],\n",
    "        \"oob_score\": [True],\n",
    "        \"class_weight\": [\"balanced\"],\n",
    "        \"random_state\": [42]\n",
    "    },\n",
    "    scoring=\"f1\",\n",
    "    verbose=True,\n",
    "    refit=True,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   18.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.59 s, sys: 84.4 ms, total: 3.68 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_trainer.fit(train_regressors, train_targets)\n",
    "model = model_trainer.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yp = model.predict(test_regressors)\n",
    "yt = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred   0   1\n",
       "y_true        \n",
       "0       95  47\n",
       "1       89  81"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    index=pd.Index([0, 1], name=\"y_true\"),\n",
    "    columns=pd.Index([0, 1], name=\"y_pred\"),\n",
    "    data=skmetrics.confusion_matrix(y_true=yt, y_pred=yp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.67      0.58       142\n",
      "          1       0.63      0.48      0.54       170\n",
      "\n",
      "avg / total       0.58      0.56      0.56       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print skmetrics.classification_report(y_true=yt, y_pred=yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5641025641025641"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yt, yp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
