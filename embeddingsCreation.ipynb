{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import os, codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in codecs.open(os.path.join(self.dirname, fname)) :\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sentences = MySentences('/home/bahbbc/Documents/teste-personalidade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_sentences = MySentences('/home/bahbbc/Documents/b5-post(confidencial)/normalised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "num_features = [100, 300, 600]\n",
    "min_word_count = [1, 5, 15]   # Minimum word count                       \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 5          # Context window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:39:07,936 : INFO : collecting all words and their counts\n",
      "2017-04-18 10:39:07,942 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-18 10:39:08,010 : INFO : PROGRESS: at sentence #10000, processed 98661 words, keeping 27955 word types\n",
      "2017-04-18 10:39:08,073 : INFO : PROGRESS: at sentence #20000, processed 203143 words, keeping 49341 word types\n",
      "2017-04-18 10:39:08,126 : INFO : PROGRESS: at sentence #30000, processed 292582 words, keeping 64869 word types\n",
      "2017-04-18 10:39:08,185 : INFO : PROGRESS: at sentence #40000, processed 396167 words, keeping 81156 word types\n",
      "2017-04-18 10:39:08,245 : INFO : PROGRESS: at sentence #50000, processed 493400 words, keeping 95005 word types\n",
      "2017-04-18 10:39:08,297 : INFO : PROGRESS: at sentence #60000, processed 589134 words, keeping 108568 word types\n",
      "2017-04-18 10:39:08,347 : INFO : PROGRESS: at sentence #70000, processed 676484 words, keeping 119972 word types\n",
      "2017-04-18 10:39:08,409 : INFO : PROGRESS: at sentence #80000, processed 795993 words, keeping 133590 word types\n",
      "2017-04-18 10:39:08,468 : INFO : PROGRESS: at sentence #90000, processed 906895 words, keeping 146634 word types\n",
      "2017-04-18 10:39:08,525 : INFO : PROGRESS: at sentence #100000, processed 1002821 words, keeping 158366 word types\n",
      "2017-04-18 10:39:08,586 : INFO : PROGRESS: at sentence #110000, processed 1103663 words, keeping 170182 word types\n",
      "2017-04-18 10:39:08,651 : INFO : PROGRESS: at sentence #120000, processed 1195050 words, keeping 180481 word types\n",
      "2017-04-18 10:39:08,706 : INFO : PROGRESS: at sentence #130000, processed 1285432 words, keeping 190921 word types\n",
      "2017-04-18 10:39:08,763 : INFO : PROGRESS: at sentence #140000, processed 1376866 words, keeping 200532 word types\n",
      "2017-04-18 10:39:08,819 : INFO : PROGRESS: at sentence #150000, processed 1474032 words, keeping 210517 word types\n",
      "2017-04-18 10:39:08,878 : INFO : PROGRESS: at sentence #160000, processed 1576047 words, keeping 221053 word types\n",
      "2017-04-18 10:39:08,935 : INFO : PROGRESS: at sentence #170000, processed 1670044 words, keeping 230518 word types\n",
      "2017-04-18 10:39:09,003 : INFO : PROGRESS: at sentence #180000, processed 1779374 words, keeping 241337 word types\n",
      "2017-04-18 10:39:09,085 : INFO : PROGRESS: at sentence #190000, processed 1870578 words, keeping 249592 word types\n",
      "2017-04-18 10:39:09,147 : INFO : PROGRESS: at sentence #200000, processed 1960342 words, keeping 259200 word types\n",
      "2017-04-18 10:39:09,202 : INFO : PROGRESS: at sentence #210000, processed 2051895 words, keeping 267875 word types\n",
      "2017-04-18 10:39:09,264 : INFO : PROGRESS: at sentence #220000, processed 2157737 words, keeping 277623 word types\n",
      "2017-04-18 10:39:09,320 : INFO : PROGRESS: at sentence #230000, processed 2250654 words, keeping 286187 word types\n",
      "2017-04-18 10:39:09,339 : INFO : collected 288722 word types from a corpus of 2272383 raw words and 232478 sentences\n",
      "2017-04-18 10:39:09,340 : INFO : Loading a fresh vocabulary\n",
      "2017-04-18 10:39:10,541 : INFO : min_count=1 retains 288722 unique words (100% of original 288722, drops 0)\n",
      "2017-04-18 10:39:10,542 : INFO : min_count=1 leaves 2272383 word corpus (100% of original 2272383, drops 0)\n",
      "2017-04-18 10:39:11,198 : INFO : deleting the raw counts dictionary of 288722 items\n",
      "2017-04-18 10:39:11,204 : INFO : sample=0.001 downsamples 32 most-common words\n",
      "2017-04-18 10:39:11,205 : INFO : downsampling leaves estimated 1953527 word corpus (86.0% of prior 2272383)\n",
      "2017-04-18 10:39:11,206 : INFO : estimated required memory for 288722 words and 100 dimensions: 375338600 bytes\n",
      "2017-04-18 10:39:11,979 : INFO : resetting layer weights\n",
      "2017-04-18 10:39:14,707 : INFO : training model with 4 workers on 288722 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-18 10:39:14,707 : INFO : expecting 232478 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-18 10:39:15,727 : INFO : PROGRESS: at 2.84% examples, 271373 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:16,729 : INFO : PROGRESS: at 5.95% examples, 284960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:39:17,744 : INFO : PROGRESS: at 8.65% examples, 284941 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:18,766 : INFO : PROGRESS: at 11.56% examples, 281088 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:19,792 : INFO : PROGRESS: at 14.77% examples, 285266 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:20,868 : INFO : PROGRESS: at 17.80% examples, 282658 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:21,915 : INFO : PROGRESS: at 20.35% examples, 276283 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:23,032 : INFO : PROGRESS: at 22.60% examples, 265040 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:24,046 : INFO : PROGRESS: at 25.76% examples, 269250 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:25,068 : INFO : PROGRESS: at 28.58% examples, 271467 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:26,077 : INFO : PROGRESS: at 31.77% examples, 273896 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:27,101 : INFO : PROGRESS: at 34.51% examples, 272731 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:28,134 : INFO : PROGRESS: at 37.36% examples, 272200 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:29,158 : INFO : PROGRESS: at 40.30% examples, 272761 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:30,148 : INFO : PROGRESS: at 43.35% examples, 274545 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:39:31,171 : INFO : PROGRESS: at 46.28% examples, 275096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:32,224 : INFO : PROGRESS: at 48.15% examples, 269755 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:33,249 : INFO : PROGRESS: at 50.31% examples, 266008 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:34,266 : INFO : PROGRESS: at 52.57% examples, 263173 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:35,317 : INFO : PROGRESS: at 55.11% examples, 261832 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:36,350 : INFO : PROGRESS: at 58.41% examples, 263609 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:37,360 : INFO : PROGRESS: at 61.04% examples, 263618 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:38,367 : INFO : PROGRESS: at 64.15% examples, 265096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:39,369 : INFO : PROGRESS: at 67.10% examples, 266422 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:40,408 : INFO : PROGRESS: at 70.10% examples, 267353 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:41,418 : INFO : PROGRESS: at 73.10% examples, 267563 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:42,442 : INFO : PROGRESS: at 76.10% examples, 268474 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:43,464 : INFO : PROGRESS: at 79.13% examples, 269096 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:44,467 : INFO : PROGRESS: at 82.30% examples, 270172 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:45,486 : INFO : PROGRESS: at 84.94% examples, 269831 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-18 10:39:46,492 : INFO : PROGRESS: at 87.84% examples, 270646 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:39:47,495 : INFO : PROGRESS: at 90.99% examples, 271549 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:48,555 : INFO : PROGRESS: at 93.20% examples, 269160 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:49,569 : INFO : PROGRESS: at 96.11% examples, 269685 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:50,575 : INFO : PROGRESS: at 98.57% examples, 268404 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:39:51,151 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-18 10:39:51,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-18 10:39:51,162 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-18 10:39:51,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-18 10:39:51,173 : INFO : training on 11361915 raw words (9768848 effective words) took 36.5s, 267926 effective words/s\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_1 = gensim.models.Word2Vec(raw_sentences, workers=num_workers, \\\n",
    "            size=num_features[0], min_count = min_word_count[0], window = context, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:43:42,645 : INFO : collecting all words and their counts\n",
      "2017-04-18 10:43:42,653 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-18 10:43:42,717 : INFO : PROGRESS: at sentence #10000, processed 98661 words, keeping 27955 word types\n",
      "2017-04-18 10:43:42,762 : INFO : PROGRESS: at sentence #20000, processed 203143 words, keeping 49341 word types\n",
      "2017-04-18 10:43:42,801 : INFO : PROGRESS: at sentence #30000, processed 292582 words, keeping 64869 word types\n",
      "2017-04-18 10:43:42,839 : INFO : PROGRESS: at sentence #40000, processed 396167 words, keeping 81156 word types\n",
      "2017-04-18 10:43:42,893 : INFO : PROGRESS: at sentence #50000, processed 493400 words, keeping 95005 word types\n",
      "2017-04-18 10:43:42,933 : INFO : PROGRESS: at sentence #60000, processed 589134 words, keeping 108568 word types\n",
      "2017-04-18 10:43:42,971 : INFO : PROGRESS: at sentence #70000, processed 676484 words, keeping 119972 word types\n",
      "2017-04-18 10:43:43,017 : INFO : PROGRESS: at sentence #80000, processed 795993 words, keeping 133590 word types\n",
      "2017-04-18 10:43:43,063 : INFO : PROGRESS: at sentence #90000, processed 906895 words, keeping 146634 word types\n",
      "2017-04-18 10:43:43,104 : INFO : PROGRESS: at sentence #100000, processed 1002821 words, keeping 158366 word types\n",
      "2017-04-18 10:43:43,146 : INFO : PROGRESS: at sentence #110000, processed 1103663 words, keeping 170182 word types\n",
      "2017-04-18 10:43:43,195 : INFO : PROGRESS: at sentence #120000, processed 1195050 words, keeping 180481 word types\n",
      "2017-04-18 10:43:43,236 : INFO : PROGRESS: at sentence #130000, processed 1285432 words, keeping 190921 word types\n",
      "2017-04-18 10:43:43,277 : INFO : PROGRESS: at sentence #140000, processed 1376866 words, keeping 200532 word types\n",
      "2017-04-18 10:43:43,320 : INFO : PROGRESS: at sentence #150000, processed 1474032 words, keeping 210517 word types\n",
      "2017-04-18 10:43:43,369 : INFO : PROGRESS: at sentence #160000, processed 1576047 words, keeping 221053 word types\n",
      "2017-04-18 10:43:43,414 : INFO : PROGRESS: at sentence #170000, processed 1670044 words, keeping 230518 word types\n",
      "2017-04-18 10:43:43,473 : INFO : PROGRESS: at sentence #180000, processed 1779374 words, keeping 241337 word types\n",
      "2017-04-18 10:43:43,519 : INFO : PROGRESS: at sentence #190000, processed 1870578 words, keeping 249592 word types\n",
      "2017-04-18 10:43:43,568 : INFO : PROGRESS: at sentence #200000, processed 1960342 words, keeping 259200 word types\n",
      "2017-04-18 10:43:43,609 : INFO : PROGRESS: at sentence #210000, processed 2051895 words, keeping 267875 word types\n",
      "2017-04-18 10:43:43,657 : INFO : PROGRESS: at sentence #220000, processed 2157737 words, keeping 277623 word types\n",
      "2017-04-18 10:43:43,702 : INFO : PROGRESS: at sentence #230000, processed 2250654 words, keeping 286187 word types\n",
      "2017-04-18 10:43:43,720 : INFO : collected 288722 word types from a corpus of 2272383 raw words and 232478 sentences\n",
      "2017-04-18 10:43:43,720 : INFO : Loading a fresh vocabulary\n",
      "2017-04-18 10:43:43,977 : INFO : min_count=5 retains 34378 unique words (11% of original 288722, drops 254344)\n",
      "2017-04-18 10:43:43,978 : INFO : min_count=5 leaves 1926717 word corpus (84% of original 2272383, drops 345666)\n",
      "2017-04-18 10:43:44,070 : INFO : deleting the raw counts dictionary of 288722 items\n",
      "2017-04-18 10:43:44,086 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-04-18 10:43:44,087 : INFO : downsampling leaves estimated 1580285 word corpus (82.0% of prior 1926717)\n",
      "2017-04-18 10:43:44,089 : INFO : estimated required memory for 34378 words and 300 dimensions: 99696200 bytes\n",
      "2017-04-18 10:43:44,209 : INFO : resetting layer weights\n",
      "2017-04-18 10:43:44,643 : INFO : training model with 4 workers on 34378 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-18 10:43:44,644 : INFO : expecting 232478 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-18 10:43:45,664 : INFO : PROGRESS: at 2.14% examples, 163519 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:46,679 : INFO : PROGRESS: at 4.76% examples, 188272 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:47,708 : INFO : PROGRESS: at 7.30% examples, 192500 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:48,708 : INFO : PROGRESS: at 9.83% examples, 196348 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:43:49,712 : INFO : PROGRESS: at 12.61% examples, 198580 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:50,740 : INFO : PROGRESS: at 15.09% examples, 197068 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:51,757 : INFO : PROGRESS: at 17.90% examples, 199091 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:52,788 : INFO : PROGRESS: at 20.71% examples, 201115 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:53,810 : INFO : PROGRESS: at 23.39% examples, 202121 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:54,836 : INFO : PROGRESS: at 25.98% examples, 200801 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:55,889 : INFO : PROGRESS: at 28.48% examples, 201752 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:56,968 : INFO : PROGRESS: at 31.51% examples, 202691 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:58,001 : INFO : PROGRESS: at 34.34% examples, 203699 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:43:59,016 : INFO : PROGRESS: at 37.19% examples, 204776 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:00,040 : INFO : PROGRESS: at 39.56% examples, 203310 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:01,047 : INFO : PROGRESS: at 42.34% examples, 203923 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:02,119 : INFO : PROGRESS: at 45.00% examples, 203705 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:03,128 : INFO : PROGRESS: at 47.08% examples, 201990 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:04,185 : INFO : PROGRESS: at 49.38% examples, 200634 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:05,220 : INFO : PROGRESS: at 52.00% examples, 199995 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:06,260 : INFO : PROGRESS: at 54.82% examples, 200687 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:07,294 : INFO : PROGRESS: at 57.67% examples, 201326 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:08,295 : INFO : PROGRESS: at 60.40% examples, 201885 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:09,419 : INFO : PROGRESS: at 62.96% examples, 200928 words/s, in_qsize 7, out_qsize 1\n",
      "2017-04-18 10:44:10,441 : INFO : PROGRESS: at 65.93% examples, 201760 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:11,459 : INFO : PROGRESS: at 68.33% examples, 202134 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:12,466 : INFO : PROGRESS: at 71.09% examples, 202287 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:13,515 : INFO : PROGRESS: at 73.40% examples, 201218 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:14,567 : INFO : PROGRESS: at 75.86% examples, 200645 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:15,579 : INFO : PROGRESS: at 78.71% examples, 201259 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:16,626 : INFO : PROGRESS: at 81.45% examples, 201375 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:17,644 : INFO : PROGRESS: at 84.26% examples, 201887 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:18,645 : INFO : PROGRESS: at 86.90% examples, 202266 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:19,669 : INFO : PROGRESS: at 89.17% examples, 201664 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:20,699 : INFO : PROGRESS: at 92.21% examples, 202271 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:21,706 : INFO : PROGRESS: at 94.95% examples, 202592 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:22,735 : INFO : PROGRESS: at 97.72% examples, 202761 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:23,466 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-18 10:44:23,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-18 10:44:23,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-18 10:44:23,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-18 10:44:23,529 : INFO : training on 11361915 raw words (7901552 effective words) took 38.9s, 203218 effective words/s\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_2 = gensim.models.Word2Vec(raw_sentences, workers=num_workers, \\\n",
    "            size=num_features[1], min_count = min_word_count[1], window = context, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:44:23,548 : INFO : collecting all words and their counts\n",
      "2017-04-18 10:44:23,552 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-18 10:44:23,604 : INFO : PROGRESS: at sentence #10000, processed 98661 words, keeping 27955 word types\n",
      "2017-04-18 10:44:23,648 : INFO : PROGRESS: at sentence #20000, processed 203143 words, keeping 49341 word types\n",
      "2017-04-18 10:44:23,685 : INFO : PROGRESS: at sentence #30000, processed 292582 words, keeping 64869 word types\n",
      "2017-04-18 10:44:23,726 : INFO : PROGRESS: at sentence #40000, processed 396167 words, keeping 81156 word types\n",
      "2017-04-18 10:44:23,771 : INFO : PROGRESS: at sentence #50000, processed 493400 words, keeping 95005 word types\n",
      "2017-04-18 10:44:23,811 : INFO : PROGRESS: at sentence #60000, processed 589134 words, keeping 108568 word types\n",
      "2017-04-18 10:44:23,852 : INFO : PROGRESS: at sentence #70000, processed 676484 words, keeping 119972 word types\n",
      "2017-04-18 10:44:23,899 : INFO : PROGRESS: at sentence #80000, processed 795993 words, keeping 133590 word types\n",
      "2017-04-18 10:44:23,943 : INFO : PROGRESS: at sentence #90000, processed 906895 words, keeping 146634 word types\n",
      "2017-04-18 10:44:23,984 : INFO : PROGRESS: at sentence #100000, processed 1002821 words, keeping 158366 word types\n",
      "2017-04-18 10:44:24,026 : INFO : PROGRESS: at sentence #110000, processed 1103663 words, keeping 170182 word types\n",
      "2017-04-18 10:44:24,073 : INFO : PROGRESS: at sentence #120000, processed 1195050 words, keeping 180481 word types\n",
      "2017-04-18 10:44:24,114 : INFO : PROGRESS: at sentence #130000, processed 1285432 words, keeping 190921 word types\n",
      "2017-04-18 10:44:24,156 : INFO : PROGRESS: at sentence #140000, processed 1376866 words, keeping 200532 word types\n",
      "2017-04-18 10:44:24,199 : INFO : PROGRESS: at sentence #150000, processed 1474032 words, keeping 210517 word types\n",
      "2017-04-18 10:44:24,244 : INFO : PROGRESS: at sentence #160000, processed 1576047 words, keeping 221053 word types\n",
      "2017-04-18 10:44:24,287 : INFO : PROGRESS: at sentence #170000, processed 1670044 words, keeping 230518 word types\n",
      "2017-04-18 10:44:24,333 : INFO : PROGRESS: at sentence #180000, processed 1779374 words, keeping 241337 word types\n",
      "2017-04-18 10:44:24,375 : INFO : PROGRESS: at sentence #190000, processed 1870578 words, keeping 249592 word types\n",
      "2017-04-18 10:44:24,417 : INFO : PROGRESS: at sentence #200000, processed 1960342 words, keeping 259200 word types\n",
      "2017-04-18 10:44:24,460 : INFO : PROGRESS: at sentence #210000, processed 2051895 words, keeping 267875 word types\n",
      "2017-04-18 10:44:24,507 : INFO : PROGRESS: at sentence #220000, processed 2157737 words, keeping 277623 word types\n",
      "2017-04-18 10:44:24,548 : INFO : PROGRESS: at sentence #230000, processed 2250654 words, keeping 286187 word types\n",
      "2017-04-18 10:44:24,563 : INFO : collected 288722 word types from a corpus of 2272383 raw words and 232478 sentences\n",
      "2017-04-18 10:44:24,564 : INFO : Loading a fresh vocabulary\n",
      "2017-04-18 10:44:24,910 : INFO : min_count=5 retains 34378 unique words (11% of original 288722, drops 254344)\n",
      "2017-04-18 10:44:24,911 : INFO : min_count=5 leaves 1926717 word corpus (84% of original 2272383, drops 345666)\n",
      "2017-04-18 10:44:25,001 : INFO : deleting the raw counts dictionary of 288722 items\n",
      "2017-04-18 10:44:25,014 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2017-04-18 10:44:25,019 : INFO : downsampling leaves estimated 1580285 word corpus (82.0% of prior 1926717)\n",
      "2017-04-18 10:44:25,022 : INFO : estimated required memory for 34378 words and 600 dimensions: 182203400 bytes\n",
      "2017-04-18 10:44:25,143 : INFO : resetting layer weights\n",
      "2017-04-18 10:44:25,693 : INFO : training model with 4 workers on 34378 vocabulary and 600 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-18 10:44:25,694 : INFO : expecting 232478 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-18 10:44:26,717 : INFO : PROGRESS: at 1.15% examples, 95822 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:27,780 : INFO : PROGRESS: at 2.84% examples, 106872 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:28,843 : INFO : PROGRESS: at 4.26% examples, 108106 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:29,935 : INFO : PROGRESS: at 5.95% examples, 109634 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:31,105 : INFO : PROGRESS: at 7.13% examples, 106519 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:32,114 : INFO : PROGRESS: at 8.56% examples, 108099 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:33,127 : INFO : PROGRESS: at 10.01% examples, 109312 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:34,158 : INFO : PROGRESS: at 11.67% examples, 110030 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:44:35,159 : INFO : PROGRESS: at 13.20% examples, 110770 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:36,182 : INFO : PROGRESS: at 14.68% examples, 111255 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:37,274 : INFO : PROGRESS: at 16.11% examples, 110912 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:38,361 : INFO : PROGRESS: at 17.80% examples, 111263 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:39,499 : INFO : PROGRESS: at 19.15% examples, 110142 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:40,512 : INFO : PROGRESS: at 20.82% examples, 111047 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:41,516 : INFO : PROGRESS: at 22.32% examples, 111427 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:42,641 : INFO : PROGRESS: at 23.75% examples, 110997 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:43,652 : INFO : PROGRESS: at 25.25% examples, 111310 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:44,711 : INFO : PROGRESS: at 26.66% examples, 111331 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:45,758 : INFO : PROGRESS: at 28.07% examples, 111398 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:46,784 : INFO : PROGRESS: at 29.53% examples, 111600 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:47,964 : INFO : PROGRESS: at 31.13% examples, 110956 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:44:48,972 : INFO : PROGRESS: at 32.75% examples, 111538 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:50,094 : INFO : PROGRESS: at 34.28% examples, 111252 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:51,129 : INFO : PROGRESS: at 35.70% examples, 111371 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:52,192 : INFO : PROGRESS: at 37.36% examples, 111610 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:53,227 : INFO : PROGRESS: at 38.86% examples, 111703 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:54,253 : INFO : PROGRESS: at 40.39% examples, 111815 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:55,289 : INFO : PROGRESS: at 41.84% examples, 111868 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:56,409 : INFO : PROGRESS: at 43.35% examples, 111633 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:57,470 : INFO : PROGRESS: at 44.56% examples, 110957 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:58,488 : INFO : PROGRESS: at 46.09% examples, 111111 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:44:59,539 : INFO : PROGRESS: at 47.35% examples, 110967 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:45:00,557 : INFO : PROGRESS: at 48.79% examples, 111073 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:01,580 : INFO : PROGRESS: at 50.31% examples, 111220 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:45:02,617 : INFO : PROGRESS: at 51.88% examples, 111278 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:03,634 : INFO : PROGRESS: at 53.39% examples, 111409 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:04,677 : INFO : PROGRESS: at 54.91% examples, 111458 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:05,708 : INFO : PROGRESS: at 56.35% examples, 111583 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:06,823 : INFO : PROGRESS: at 57.76% examples, 111036 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:07,873 : INFO : PROGRESS: at 59.28% examples, 111232 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:08,889 : INFO : PROGRESS: at 60.85% examples, 111339 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:09,909 : INFO : PROGRESS: at 61.88% examples, 110641 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:10,941 : INFO : PROGRESS: at 63.19% examples, 110270 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:11,992 : INFO : PROGRESS: at 64.58% examples, 110308 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:13,011 : INFO : PROGRESS: at 66.02% examples, 110141 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:14,014 : INFO : PROGRESS: at 67.10% examples, 110016 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:15,044 : INFO : PROGRESS: at 68.54% examples, 110102 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:16,124 : INFO : PROGRESS: at 69.82% examples, 109833 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:45:17,128 : INFO : PROGRESS: at 71.55% examples, 110101 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:18,215 : INFO : PROGRESS: at 73.10% examples, 110078 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:19,243 : INFO : PROGRESS: at 74.56% examples, 110171 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:20,260 : INFO : PROGRESS: at 76.02% examples, 110275 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:21,269 : INFO : PROGRESS: at 77.61% examples, 110397 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:22,287 : INFO : PROGRESS: at 78.96% examples, 110367 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:23,351 : INFO : PROGRESS: at 80.53% examples, 110377 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:24,353 : INFO : PROGRESS: at 82.01% examples, 110501 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:25,532 : INFO : PROGRESS: at 83.38% examples, 110169 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:26,536 : INFO : PROGRESS: at 84.94% examples, 110395 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:27,573 : INFO : PROGRESS: at 86.42% examples, 110461 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:28,587 : INFO : PROGRESS: at 87.68% examples, 110445 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:29,678 : INFO : PROGRESS: at 89.17% examples, 110394 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:30,752 : INFO : PROGRESS: at 90.77% examples, 110504 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:31,788 : INFO : PROGRESS: at 92.36% examples, 110561 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:32,835 : INFO : PROGRESS: at 93.69% examples, 110395 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:33,881 : INFO : PROGRESS: at 94.95% examples, 110127 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:34,901 : INFO : PROGRESS: at 96.49% examples, 110310 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:35,926 : INFO : PROGRESS: at 98.09% examples, 110380 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:36,976 : INFO : PROGRESS: at 99.53% examples, 110409 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-18 10:45:37,142 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-18 10:45:37,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-18 10:45:37,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-18 10:45:37,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-18 10:45:37,226 : INFO : training on 11361915 raw words (7902462 effective words) took 71.5s, 110483 effective words/s\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_3 = gensim.models.Word2Vec(raw_sentences, workers=num_workers, \\\n",
    "            size=num_features[2], min_count = min_word_count[1], window = context, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:45:37,235 : INFO : collecting all words and their counts\n",
      "2017-04-18 10:45:37,237 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-18 10:45:37,288 : INFO : PROGRESS: at sentence #10000, processed 98661 words, keeping 27955 word types\n",
      "2017-04-18 10:45:37,328 : INFO : PROGRESS: at sentence #20000, processed 203143 words, keeping 49341 word types\n",
      "2017-04-18 10:45:37,366 : INFO : PROGRESS: at sentence #30000, processed 292582 words, keeping 64869 word types\n",
      "2017-04-18 10:45:37,406 : INFO : PROGRESS: at sentence #40000, processed 396167 words, keeping 81156 word types\n",
      "2017-04-18 10:45:37,450 : INFO : PROGRESS: at sentence #50000, processed 493400 words, keeping 95005 word types\n",
      "2017-04-18 10:45:37,492 : INFO : PROGRESS: at sentence #60000, processed 589134 words, keeping 108568 word types\n",
      "2017-04-18 10:45:37,533 : INFO : PROGRESS: at sentence #70000, processed 676484 words, keeping 119972 word types\n",
      "2017-04-18 10:45:37,579 : INFO : PROGRESS: at sentence #80000, processed 795993 words, keeping 133590 word types\n",
      "2017-04-18 10:45:37,624 : INFO : PROGRESS: at sentence #90000, processed 906895 words, keeping 146634 word types\n",
      "2017-04-18 10:45:37,664 : INFO : PROGRESS: at sentence #100000, processed 1002821 words, keeping 158366 word types\n",
      "2017-04-18 10:45:37,706 : INFO : PROGRESS: at sentence #110000, processed 1103663 words, keeping 170182 word types\n",
      "2017-04-18 10:45:37,753 : INFO : PROGRESS: at sentence #120000, processed 1195050 words, keeping 180481 word types\n",
      "2017-04-18 10:45:37,794 : INFO : PROGRESS: at sentence #130000, processed 1285432 words, keeping 190921 word types\n",
      "2017-04-18 10:45:37,835 : INFO : PROGRESS: at sentence #140000, processed 1376866 words, keeping 200532 word types\n",
      "2017-04-18 10:45:37,885 : INFO : PROGRESS: at sentence #150000, processed 1474032 words, keeping 210517 word types\n",
      "2017-04-18 10:45:37,933 : INFO : PROGRESS: at sentence #160000, processed 1576047 words, keeping 221053 word types\n",
      "2017-04-18 10:45:37,980 : INFO : PROGRESS: at sentence #170000, processed 1670044 words, keeping 230518 word types\n",
      "2017-04-18 10:45:38,039 : INFO : PROGRESS: at sentence #180000, processed 1779374 words, keeping 241337 word types\n",
      "2017-04-18 10:45:38,080 : INFO : PROGRESS: at sentence #190000, processed 1870578 words, keeping 249592 word types\n",
      "2017-04-18 10:45:38,122 : INFO : PROGRESS: at sentence #200000, processed 1960342 words, keeping 259200 word types\n",
      "2017-04-18 10:45:38,164 : INFO : PROGRESS: at sentence #210000, processed 2051895 words, keeping 267875 word types\n",
      "2017-04-18 10:45:38,210 : INFO : PROGRESS: at sentence #220000, processed 2157737 words, keeping 277623 word types\n",
      "2017-04-18 10:45:38,252 : INFO : PROGRESS: at sentence #230000, processed 2250654 words, keeping 286187 word types\n",
      "2017-04-18 10:45:38,268 : INFO : collected 288722 word types from a corpus of 2272383 raw words and 232478 sentences\n",
      "2017-04-18 10:45:38,269 : INFO : Loading a fresh vocabulary\n",
      "2017-04-18 10:45:38,453 : INFO : min_count=15 retains 12301 unique words (4% of original 288722, drops 276421)\n",
      "2017-04-18 10:45:38,454 : INFO : min_count=15 leaves 1755166 word corpus (77% of original 2272383, drops 517217)\n",
      "2017-04-18 10:45:38,491 : INFO : deleting the raw counts dictionary of 288722 items\n",
      "2017-04-18 10:45:38,510 : INFO : sample=0.001 downsamples 42 most-common words\n",
      "2017-04-18 10:45:38,511 : INFO : downsampling leaves estimated 1392937 word corpus (79.4% of prior 1755166)\n",
      "2017-04-18 10:45:38,513 : INFO : estimated required memory for 12301 words and 600 dimensions: 65195300 bytes\n",
      "2017-04-18 10:45:38,562 : INFO : resetting layer weights\n",
      "2017-04-18 10:45:38,761 : INFO : training model with 4 workers on 12301 vocabulary and 600 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-04-18 10:45:38,761 : INFO : expecting 232478 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-18 10:45:39,824 : INFO : PROGRESS: at 1.79% examples, 121484 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:40,854 : INFO : PROGRESS: at 3.91% examples, 131590 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:41,865 : INFO : PROGRESS: at 5.65% examples, 126281 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:42,949 : INFO : PROGRESS: at 7.48% examples, 127057 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:44,050 : INFO : PROGRESS: at 9.50% examples, 128499 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:45,060 : INFO : PROGRESS: at 11.74% examples, 131125 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:46,076 : INFO : PROGRESS: at 13.69% examples, 131364 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:47,150 : INFO : PROGRESS: at 15.79% examples, 132162 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:48,189 : INFO : PROGRESS: at 17.62% examples, 130524 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:49,189 : INFO : PROGRESS: at 19.62% examples, 131505 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:50,211 : INFO : PROGRESS: at 21.55% examples, 131476 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:51,275 : INFO : PROGRESS: at 23.65% examples, 131997 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:52,279 : INFO : PROGRESS: at 25.76% examples, 132613 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:53,304 : INFO : PROGRESS: at 27.49% examples, 132522 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:54,328 : INFO : PROGRESS: at 29.43% examples, 132914 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:55,379 : INFO : PROGRESS: at 31.41% examples, 132196 words/s, in_qsize 7, out_qsize 0\n",
      "2017-04-18 10:45:56,418 : INFO : PROGRESS: at 33.42% examples, 132386 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:57,494 : INFO : PROGRESS: at 35.38% examples, 132332 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:58,568 : INFO : PROGRESS: at 37.75% examples, 132877 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:45:59,572 : INFO : PROGRESS: at 39.75% examples, 133232 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:00,589 : INFO : PROGRESS: at 41.74% examples, 133427 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:01,634 : INFO : PROGRESS: at 43.45% examples, 132387 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:02,666 : INFO : PROGRESS: at 45.62% examples, 132832 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:03,671 : INFO : PROGRESS: at 47.35% examples, 132869 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:04,688 : INFO : PROGRESS: at 49.23% examples, 132826 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:05,756 : INFO : PROGRESS: at 51.54% examples, 133255 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:06,766 : INFO : PROGRESS: at 53.55% examples, 133486 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:07,804 : INFO : PROGRESS: at 55.40% examples, 133370 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:08,816 : INFO : PROGRESS: at 57.29% examples, 132975 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:09,826 : INFO : PROGRESS: at 59.28% examples, 133158 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:10,919 : INFO : PROGRESS: at 61.41% examples, 133180 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:11,961 : INFO : PROGRESS: at 63.53% examples, 133406 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:12,982 : INFO : PROGRESS: at 65.64% examples, 133533 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:14,042 : INFO : PROGRESS: at 67.36% examples, 133342 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:15,168 : INFO : PROGRESS: at 69.24% examples, 132908 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:16,250 : INFO : PROGRESS: at 71.55% examples, 133155 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:17,286 : INFO : PROGRESS: at 73.68% examples, 133401 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:18,339 : INFO : PROGRESS: at 75.76% examples, 133571 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:19,370 : INFO : PROGRESS: at 77.78% examples, 133473 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:20,377 : INFO : PROGRESS: at 79.90% examples, 133769 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:21,474 : INFO : PROGRESS: at 81.61% examples, 133185 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:22,545 : INFO : PROGRESS: at 83.72% examples, 133271 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:23,588 : INFO : PROGRESS: at 85.95% examples, 133447 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:24,603 : INFO : PROGRESS: at 87.68% examples, 133558 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:25,617 : INFO : PROGRESS: at 89.58% examples, 133544 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:26,633 : INFO : PROGRESS: at 91.83% examples, 133763 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:27,645 : INFO : PROGRESS: at 93.54% examples, 133382 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:28,691 : INFO : PROGRESS: at 95.49% examples, 133420 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:29,735 : INFO : PROGRESS: at 97.72% examples, 133558 words/s, in_qsize 8, out_qsize 0\n",
      "2017-04-18 10:46:30,731 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-04-18 10:46:30,783 : INFO : PROGRESS: at 99.83% examples, 133685 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-18 10:46:30,788 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-18 10:46:30,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-18 10:46:30,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-18 10:46:30,800 : INFO : training on 11361915 raw words (6964121 effective words) took 52.0s, 133844 effective words/s\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_4 = gensim.models.Word2Vec(raw_sentences, workers=num_workers, \\\n",
    "            size=num_features[2], min_count = min_word_count[2], window = context, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:48:41,109 : INFO : saving Word2Vec object under /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_1.model, separately None\n",
      "2017-04-18 10:48:41,111 : INFO : not storing attribute syn0norm\n",
      "2017-04-18 10:48:41,113 : INFO : storing np array 'syn0' to /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_1.model.wv.syn0.npy\n",
      "2017-04-18 10:48:44,166 : INFO : saved /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_1.model\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_1.save('/home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:49:04,690 : INFO : saving Word2Vec object under /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_2.model, separately None\n",
      "2017-04-18 10:49:04,696 : INFO : not storing attribute syn0norm\n",
      "2017-04-18 10:49:04,698 : INFO : not storing attribute cum_table\n",
      "2017-04-18 10:49:05,218 : INFO : saved /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_2.model\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_2.save('/home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:49:05,648 : INFO : saving Word2Vec object under /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_3.model, separately None\n",
      "2017-04-18 10:49:05,654 : INFO : not storing attribute syn0norm\n",
      "2017-04-18 10:49:05,657 : INFO : storing np array 'syn0' to /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_3.model.wv.syn0.npy\n",
      "2017-04-18 10:49:05,717 : INFO : storing np array 'syn1neg' to /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_3.model.syn1neg.npy\n",
      "2017-04-18 10:49:05,888 : INFO : not storing attribute cum_table\n",
      "2017-04-18 10:49:06,182 : INFO : saved /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_3.model\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_3.save('/home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-18 10:49:06,616 : INFO : saving Word2Vec object under /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_4.model, separately None\n",
      "2017-04-18 10:49:06,625 : INFO : not storing attribute syn0norm\n",
      "2017-04-18 10:49:06,627 : INFO : not storing attribute cum_table\n",
      "2017-04-18 10:49:07,001 : INFO : saved /home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_4.model\n"
     ]
    }
   ],
   "source": [
    "skip_gram_simple_model_4.save('/home/bahbbc/workspace/masters-big5/models/skip_gram_simple_model_4.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluatiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('/home/bahbbc/Documents/personality_norm')\n",
    "model.init_sims(replace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
