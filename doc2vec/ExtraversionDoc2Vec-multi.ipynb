{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-07 23:39:23,751 : INFO : 'pattern' package found; tag filters are available for English\n",
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "import os, codecs\n",
    "%matplotlib inline\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics as skmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify model with personality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/personality-normalized-word2vec-norm.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1039, 186)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    529\n",
       "1    510\n",
       "Name: extraversion_m, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.extraversion_m.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_w2v_data, test_w2v_data = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    target_names = ['no', 'yes']\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    cm = confusion_matrix(target, predictions)\n",
    "    print('confusion matrix\\n %s' % cm)\n",
    "    print('(row=expected, col=predicted)')\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized, title + ' Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(vectorizer, classifier, data):\n",
    "    data_features = vectorizer.transform(data['formatted_text'])\n",
    "    predictions = classifier.predict(data_features)\n",
    "    target = int(data['extraversion'])\n",
    "    evaluate_prediction(predictions, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    if text is np.nan:\n",
    "        return []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tagged = train_w2v_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['formatted_text']), tags=[int(r.extraversion)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tagged = test_w2v_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['formatted_text']), tags=[int(r.extraversion)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-07 23:40:09,455 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-07-07 23:40:09,457 : INFO : collecting all words and their counts\n",
      "2017-07-07 23:40:09,458 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2017-07-07 23:40:09,805 : INFO : collected 43446 word types and 6 unique tags from a corpus of 727 examples and 1472087 words\n",
      "2017-07-07 23:40:09,806 : INFO : Loading a fresh vocabulary\n",
      "2017-07-07 23:40:10,029 : INFO : min_count=5 retains 13634 unique words (31% of original 43446, drops 29812)\n",
      "2017-07-07 23:40:10,030 : INFO : min_count=5 leaves 1421890 word corpus (96% of original 1472087, drops 50197)\n",
      "2017-07-07 23:40:10,065 : INFO : deleting the raw counts dictionary of 43446 items\n",
      "2017-07-07 23:40:10,067 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-07-07 23:40:10,068 : INFO : downsampling leaves estimated 1039507 word corpus (73.1% of prior 1421890)\n",
      "2017-07-07 23:40:10,069 : INFO : estimated required memory for 13634 words and 5 dimensions: 7362480 bytes\n",
      "2017-07-07 23:40:10,113 : INFO : resetting layer weights\n",
      "2017-07-07 23:40:10,264 : INFO : training model with 1 workers on 13634 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-07-07 23:40:10,264 : INFO : expecting 727 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-07-07 23:40:11,284 : INFO : PROGRESS: at 3.09% examples, 653293 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:12,284 : INFO : PROGRESS: at 5.95% examples, 608716 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:13,289 : INFO : PROGRESS: at 8.90% examples, 614622 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:14,295 : INFO : PROGRESS: at 11.84% examples, 613467 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:15,309 : INFO : PROGRESS: at 14.83% examples, 608047 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:16,311 : INFO : PROGRESS: at 17.50% examples, 603941 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:17,314 : INFO : PROGRESS: at 20.80% examples, 611701 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:18,321 : INFO : PROGRESS: at 23.80% examples, 612368 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:19,325 : INFO : PROGRESS: at 26.69% examples, 613019 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:20,336 : INFO : PROGRESS: at 29.83% examples, 613062 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:21,339 : INFO : PROGRESS: at 32.63% examples, 612717 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:22,345 : INFO : PROGRESS: at 35.92% examples, 615499 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:23,355 : INFO : PROGRESS: at 39.27% examples, 621622 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:24,357 : INFO : PROGRESS: at 42.59% examples, 627950 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:25,364 : INFO : PROGRESS: at 46.21% examples, 633668 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:26,371 : INFO : PROGRESS: at 49.62% examples, 638332 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:27,375 : INFO : PROGRESS: at 52.77% examples, 639876 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:28,376 : INFO : PROGRESS: at 56.27% examples, 643246 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:29,384 : INFO : PROGRESS: at 59.53% examples, 644997 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:30,390 : INFO : PROGRESS: at 62.65% examples, 645829 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:31,391 : INFO : PROGRESS: at 66.03% examples, 646969 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:32,391 : INFO : PROGRESS: at 69.41% examples, 649820 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:33,395 : INFO : PROGRESS: at 72.54% examples, 650452 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:34,401 : INFO : PROGRESS: at 75.96% examples, 651574 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:35,406 : INFO : PROGRESS: at 79.13% examples, 651707 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:36,409 : INFO : PROGRESS: at 82.35% examples, 653308 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:37,419 : INFO : PROGRESS: at 86.03% examples, 655785 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:38,425 : INFO : PROGRESS: at 89.44% examples, 657813 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:39,426 : INFO : PROGRESS: at 92.58% examples, 658080 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:40,429 : INFO : PROGRESS: at 95.96% examples, 658575 words/s, in_qsize 1, out_qsize 0\n",
      "2017-07-07 23:40:41,432 : INFO : PROGRESS: at 99.13% examples, 658501 words/s, in_qsize 2, out_qsize 0\n",
      "2017-07-07 23:40:41,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-07-07 23:40:41,690 : INFO : training on 29441740 raw words (20698345 effective words) took 31.4s, 658669 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.3 s, sys: 188 ms, total: 55.5 s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainsent = train_tagged.values\n",
    "testsent = test_tagged.values\n",
    "\n",
    "# simple gensim doc2vec api\n",
    "doc2vec_model = Doc2Vec(trainsent, workers=1, size=5, iter=20, dm=1)\n",
    "\n",
    "train_targets, train_regressors = zip(\n",
    "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in trainsent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 1422\n",
    "\n",
    "doc2vec_model.seed = seed\n",
    "doc2vec_model.random = random.RandomState(seed)\n",
    "\n",
    "\n",
    "test_targets, test_regressors = zip(\n",
    "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in testsent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "force = False\n",
    "model_trainer = RandomizedSearchCV(\n",
    "    n_iter=1, \n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_distributions={\n",
    "        \"criterion\": [\"gini\"],\n",
    "        \"n_estimators\": [1000],\n",
    "        \"max_features\": [\"log2\"],\n",
    "        \"max_depth\": [None],\n",
    "        \"bootstrap\": [True],\n",
    "        \"oob_score\": [True],\n",
    "        \"class_weight\": [\"balanced\"],\n",
    "        \"random_state\": [42]\n",
    "    },\n",
    "    verbose=True,\n",
    "    refit=True,\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.62 s, sys: 102 ms, total: 3.72 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_trainer.fit(train_regressors, train_targets)\n",
    "model = model_trainer.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yp = model.predict(test_regressors)\n",
    "yt = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_pred</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_pred  1   2   3   4  5\n",
       "y_true                  \n",
       "1       1  16   7   1  0\n",
       "2       3  36  38   8  0\n",
       "3       5  47  66  13  0\n",
       "4       1  24  37   7  0\n",
       "5       0   1   1   0  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    index=pd.Index([1, 2, 3, 4, 5], name=\"y_true\"),\n",
    "    columns=pd.Index([1, 2, 3, 4, 5], name=\"y_pred\"),\n",
    "    data=skmetrics.confusion_matrix(y_true=yt, y_pred=yp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.10      0.04      0.06        25\n",
      "          2       0.29      0.42      0.34        85\n",
      "          3       0.44      0.50      0.47       131\n",
      "          4       0.24      0.10      0.14        69\n",
      "          5       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.33      0.35      0.33       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print skmetrics.classification_report(y_true=yt, y_pred=yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(yt, yp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
